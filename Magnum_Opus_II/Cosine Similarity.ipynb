{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnum Opus Task II - Cosine Distance/similarity between two documents\n",
    "(Two documents used are Indian cuisine & Nepali cuisine obtained from wikipedia)\n",
    "Ayush Karn - 17BCE2381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx   #to read docx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "document1 = Document('Indian Cuisine.docx')  #Document for indian cuisine\n",
    "doc1=\"\"\n",
    "for para in document1.paragraphs:\n",
    "    temp=para.text\n",
    "    doc1=doc1+temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "document2 = Document('Nepali Cuisine.docx')   #Document for nepali cuisine\n",
    "doc2=\"\"\n",
    "for para in document2.paragraphs:\n",
    "    temp=para.text\n",
    "    doc2=doc2+temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity:  0.2570134622843176\n"
     ]
    }
   ],
   "source": [
    "# tokenization \n",
    "Doc1_list = word_tokenize(doc1)  \n",
    "Doc2_list = word_tokenize(doc2) \n",
    "  \n",
    "# sw contains the list of stopwords \n",
    "sw = stopwords.words('english')  \n",
    "l1 =[];l2 =[] \n",
    "  \n",
    "# remove stop words from string \n",
    "Doc1_set = {w for w in Doc1_list if not w in sw}  #excluding the stop words from doc1 tokens\n",
    "Doc2_set = {w for w in Doc2_list if not w in sw}  #excluding the stop words from doc2 tokens\n",
    "  \n",
    "# form a set containing keywords of both strings  \n",
    "rvector = Doc1_set.union(Doc2_set)  \n",
    "for w in rvector: \n",
    "    if w in Doc1_set: l1.append(1) # create a vector \n",
    "    else: l1.append(0) \n",
    "    if w in Doc2_set: l2.append(1) \n",
    "    else: l2.append(0) \n",
    "c = 0\n",
    "  \n",
    "# cosine formula  \n",
    "for i in range(len(rvector)): \n",
    "        c+= l1[i]*l2[i] \n",
    "cosine = c / float((sum(l1)*sum(l2))**0.5) \n",
    "print(\"Cosine similarity: \", cosine) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hence cosine similarity obtained before stemming is approximately 0.257 between the two documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indian\n",
      "cuisin\n",
      "indian\n",
      "cuisin\n",
      "consist\n",
      "of\n",
      "a\n",
      "wide\n",
      "varieti\n",
      "of\n",
      "region\n",
      "and\n",
      "tradit\n",
      "cuisin\n",
      "nativ\n",
      "to\n",
      "the\n",
      "indian\n",
      "subcontin\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "sno = nltk.stem.SnowballStemmer('english')\n",
    "Doc1_stemmed = []      #Stemming Doc1 tokens\n",
    "for sentence in Doc1_list:\n",
    "    Doc1_stemmed.append(\" \".join([sno.stem(i) for i in sentence.split()]))\n",
    " \n",
    "for item in Doc1_stemmed [0:20]:  #display 0-20 stemmed words for example output\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nepali\n",
      "cuisinenepali/nepales\n",
      "cuisin\n",
      "compris\n",
      "a\n",
      "varieti\n",
      "of\n",
      "cuisin\n",
      "base\n",
      "upon\n",
      "ethnic\n",
      ",\n",
      "soil\n",
      "and\n",
      "climat\n",
      "relat\n",
      "to\n",
      "nepal\n",
      "'s\n",
      "cultur\n"
     ]
    }
   ],
   "source": [
    "Doc2_stemmed = []    #Stemming Doc 2 tokens\n",
    "for sentence in Doc2_list:\n",
    "    Doc2_stemmed.append(\" \".join([sno.stem(i) for i in sentence.split()]))\n",
    " \n",
    "for item in Doc2_stemmed [0:20]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity:  0.28832231219045157\n"
     ]
    }
   ],
   "source": [
    "# sw contains the list of stopwords \n",
    "sw = stopwords.words('english')  \n",
    "l1 =[];l2 =[] \n",
    "  \n",
    "# remove stop words from string \n",
    "Doc1_set = {w for w in Doc1_stemmed if not w in sw}  #excluding the stop words from doc1 tokens\n",
    "Doc2_set = {w for w in Doc2_stemmed if not w in sw}  #excluding the stop words from doc2 tokens\n",
    "  \n",
    "# form a set containing keywords of both strings  \n",
    "rvector = Doc1_set.union(Doc2_set)  \n",
    "for w in rvector: \n",
    "    if w in Doc1_set: l1.append(1) # create a vector \n",
    "    else: l1.append(0) \n",
    "    if w in Doc2_set: l2.append(1) \n",
    "    else: l2.append(0) \n",
    "c = 0\n",
    "  \n",
    "# cosine formula  \n",
    "for i in range(len(rvector)): \n",
    "        c+= l1[i]*l2[i] \n",
    "cosine = c / float((sum(l1)*sum(l2))**0.5) \n",
    "print(\"Cosine similarity: \", cosine) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hence cosine similarity obtained after stemming is approximately 0.288 between the two documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
